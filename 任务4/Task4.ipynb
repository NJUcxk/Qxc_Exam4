{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0416c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2307af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .enableHiveSupport().getOrCreate()\n",
    "df = spark.read.options(header='True', inferSchema='True', delimiter=',') \\\n",
    "  .csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b737578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembler = VectorAssembler(inputCols=[ 'total_loan','year_of_loan','interest','monthly_payment','class', 'sub_class', 'work_type', 'employer_type', 'industry',\n",
    " 'work_year',\n",
    " 'house_exist',\n",
    " 'house_loan_status',\n",
    " 'censor_status',\n",
    " 'marriage',\n",
    " 'offsprings',\n",
    " 'use',\n",
    " 'post_code',\n",
    " 'region',\n",
    " 'debt_loan_ratio',\n",
    " 'del_in_18month',\n",
    " 'scoring_low',\n",
    " 'scoring_high',\n",
    " 'pub_dero_bankrup',\n",
    " 'early_return',\n",
    " 'early_return_amount',\n",
    " 'early_return_amount_3mon',\n",
    " 'recircle_b',\n",
    " 'recircle_u',\n",
    " 'initial_list_status',\n",
    " 'title',\n",
    " 'policy_code',\n",
    " 'f0',\n",
    " 'f1',\n",
    " 'f2',\n",
    " 'f3',\n",
    " 'f4',\n",
    " 'f5',\n",
    " 'total_money'],\n",
    "outputCol='features')\n",
    "labeled_df = df_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a36221",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = labeled_df[\"is_default\",\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685f9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = labeled_df.select(['features', 'is_default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce8cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_set.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6fd5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(labelCol = 'is_default').fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16c4a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/spark-3.2.0-bin-hadoop3.2/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_result = log_reg.evaluate(test_df).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5673640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC： 0.8014095445033663\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='is_default')\n",
    "print('AUC：', evaluator.evaluate(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d7fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4389:==================>                                     (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877607356910269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4389:=====================================>                  (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(MulticlassClassificationEvaluator(labelCol=\"is_default\",predictionCol=\"prediction\", metricName=\"f1\").evaluate(test_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50bf753",
   "metadata": {},
   "source": [
    "better lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82aea2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.3 0.8014114612612473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.31 0.8014110444230913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.32 0.8014116347984709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.32999999999999996 0.8014071114940454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.33999999999999997 0.8014132951747241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.35 0.8014139378728856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.36 0.8014123385398768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.37 0.8014088233210338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.38 0.8014119025167014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.39 0.8014137782884031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.4 0.8014138846780579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.41 0.801413939616978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.42 0.8014098907057678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.43 0.801413739046317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.44 0.8014094974128638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.44999999999999996 0.8014103842840031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.45999999999999996 0.8014104880575189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.47 0.8014090317401117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.48 0.8014140111247791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.49 0.8014126158506163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.5 0.8014120638452764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.51 0.8014137407904098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.52 0.8014100537784358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.53 0.8014139335126536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.54 0.8014117490365432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.55 0.8014123873744726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.56 0.8014103729474003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.5700000000000001 0.8014097162964978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.5800000000000001 0.8014140355420767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.59 0.8014129821100844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.6 0.8014134870249217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.61 0.8014171897337303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.62 0.8014143608153659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.63 0.801412994318733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.64 0.801412572248299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.65 0.801412768458728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.6599999999999999 0.8014164999450664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.6699999999999999 0.8014135907984373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.6799999999999999 0.8014130605942559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.69 0.8014117019460404\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,40):\n",
    "    threshold = 0.3+0.01*i\n",
    "    log_reg_2 = LogisticRegression(threshold = threshold,labelCol = 'is_default').fit(train_df)\n",
    "    test_result_2 = log_reg_2.evaluate(test_df).predictions\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='is_default')\n",
    "    print('AUC：'+str(threshold), evaluator.evaluate(test_result_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b90d7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC： 0.8006012437350225\n"
     ]
    }
   ],
   "source": [
    "log_reg_2 = LogisticRegression(threshold = 0.41,labelCol = 'is_default').fit(train_df)\n",
    "test_result_2 = log_reg_2.evaluate(test_df).predictions\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='is_default')\n",
    "print('AUC：', evaluator.evaluate(test_result_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f15882",
   "metadata": {},
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86a6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"is_default\", featuresCol=\"features\",maxDepth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67afb0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/19 14:07:32 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dt_model = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3492ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred = dt_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f841f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC： 0.7556666089317783\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='is_default')\n",
    "print('AUC：', evaluator.evaluate(dt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d719d9",
   "metadata": {},
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff933ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：205gini24 0.8194834321545822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：205gini32 0.8185329671994049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：205gini40 0.8212252118992234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：205entropy24 0.8110912137195835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：205entropy32 0.8015992903530812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：205entropy40 0.80740648874693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:43:25 WARN DAGScheduler: Broadcasting large task binary with size 1027.9 KiB\n",
      "21/12/18 18:43:27 WARN DAGScheduler: Broadcasting large task binary with size 1721.8 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2010gini24 0.8542378731162448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:43:47 WARN DAGScheduler: Broadcasting large task binary with size 1005.5 KiB\n",
      "21/12/18 18:43:49 WARN DAGScheduler: Broadcasting large task binary with size 1686.1 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2010gini32 0.8538066432844814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:44:09 WARN DAGScheduler: Broadcasting large task binary with size 1001.0 KiB\n",
      "21/12/18 18:44:11 WARN DAGScheduler: Broadcasting large task binary with size 1665.4 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2010gini40 0.8541621647157527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:44:32 WARN DAGScheduler: Broadcasting large task binary with size 1457.8 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2010entropy24 0.8518293215721111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:44:53 WARN DAGScheduler: Broadcasting large task binary with size 1487.6 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2010entropy32 0.8508379340479095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:45:14 WARN DAGScheduler: Broadcasting large task binary with size 1473.4 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2010entropy40 0.8513615922015019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1027.9 KiB\n",
      "21/12/18 18:45:36 WARN DAGScheduler: Broadcasting large task binary with size 1721.8 KiB\n",
      "21/12/18 18:45:37 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "21/12/18 18:45:40 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "21/12/18 18:45:43 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/18 18:45:46 WARN DAGScheduler: Broadcasting large task binary with size 1290.1 KiB\n",
      "21/12/18 18:45:47 WARN DAGScheduler: Broadcasting large task binary with size 10.5 MiB\n",
      "21/12/18 18:45:51 WARN DAGScheduler: Broadcasting large task binary with size 1766.3 KiB\n",
      "21/12/18 18:45:53 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n",
      "21/12/18 18:45:57 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/12/18 18:46:00 WARN DAGScheduler: Broadcasting large task binary with size 9.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2015gini24 0.8604041114185099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:46:28 WARN DAGScheduler: Broadcasting large task binary with size 1005.5 KiB\n",
      "21/12/18 18:46:30 WARN DAGScheduler: Broadcasting large task binary with size 1686.1 KiB\n",
      "21/12/18 18:46:33 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/18 18:46:37 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "21/12/18 18:46:41 WARN DAGScheduler: Broadcasting large task binary with size 6.8 MiB\n",
      "21/12/18 18:46:45 WARN DAGScheduler: Broadcasting large task binary with size 1231.7 KiB\n",
      "21/12/18 18:46:47 WARN DAGScheduler: Broadcasting large task binary with size 10.2 MiB\n",
      "21/12/18 18:46:52 WARN DAGScheduler: Broadcasting large task binary with size 1689.2 KiB\n",
      "21/12/18 18:46:55 WARN DAGScheduler: Broadcasting large task binary with size 14.7 MiB\n",
      "21/12/18 18:47:00 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/12/18 18:47:04 WARN DAGScheduler: Broadcasting large task binary with size 9.3 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2015gini32 0.8605033121800783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:47:23 WARN DAGScheduler: Broadcasting large task binary with size 1001.0 KiB\n",
      "21/12/18 18:47:24 WARN DAGScheduler: Broadcasting large task binary with size 1665.4 KiB\n",
      "21/12/18 18:47:26 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/18 18:47:29 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "21/12/18 18:47:32 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n",
      "21/12/18 18:47:34 WARN DAGScheduler: Broadcasting large task binary with size 1212.1 KiB\n",
      "21/12/18 18:47:36 WARN DAGScheduler: Broadcasting large task binary with size 10.0 MiB\n",
      "21/12/18 18:47:39 WARN DAGScheduler: Broadcasting large task binary with size 1663.3 KiB\n",
      "21/12/18 18:47:42 WARN DAGScheduler: Broadcasting large task binary with size 14.5 MiB\n",
      "21/12/18 18:47:45 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/12/18 18:47:49 WARN DAGScheduler: Broadcasting large task binary with size 9.2 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2015gini40 0.8604185365677196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:48:09 WARN DAGScheduler: Broadcasting large task binary with size 1457.8 KiB\n",
      "21/12/18 18:48:10 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/12/18 18:48:12 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/18 18:48:15 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "21/12/18 18:48:17 WARN DAGScheduler: Broadcasting large task binary with size 1086.7 KiB\n",
      "21/12/18 18:48:19 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "21/12/18 18:48:22 WARN DAGScheduler: Broadcasting large task binary with size 1500.3 KiB\n",
      "21/12/18 18:48:23 WARN DAGScheduler: Broadcasting large task binary with size 12.9 MiB\n",
      "21/12/18 18:48:27 WARN DAGScheduler: Broadcasting large task binary with size 1956.5 KiB\n",
      "21/12/18 18:48:29 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2015entropy24 0.8608131940107278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:48:49 WARN DAGScheduler: Broadcasting large task binary with size 1487.6 KiB\n",
      "21/12/18 18:48:51 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "21/12/18 18:48:54 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/18 18:48:57 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/18 18:48:59 WARN DAGScheduler: Broadcasting large task binary with size 1058.0 KiB\n",
      "21/12/18 18:49:00 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "21/12/18 18:49:03 WARN DAGScheduler: Broadcasting large task binary with size 1442.3 KiB\n",
      "21/12/18 18:49:05 WARN DAGScheduler: Broadcasting large task binary with size 12.6 MiB\n",
      "21/12/18 18:49:09 WARN DAGScheduler: Broadcasting large task binary with size 1885.2 KiB\n",
      "21/12/18 18:49:11 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2015entropy32 0.8607346375257043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:49:31 WARN DAGScheduler: Broadcasting large task binary with size 1473.4 KiB\n",
      "21/12/18 18:49:32 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "21/12/18 18:49:35 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/18 18:49:39 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/18 18:49:41 WARN DAGScheduler: Broadcasting large task binary with size 1056.9 KiB\n",
      "21/12/18 18:49:43 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "21/12/18 18:49:46 WARN DAGScheduler: Broadcasting large task binary with size 1438.5 KiB\n",
      "21/12/18 18:49:48 WARN DAGScheduler: Broadcasting large task binary with size 12.6 MiB\n",
      "21/12/18 18:49:52 WARN DAGScheduler: Broadcasting large task binary with size 1858.0 KiB\n",
      "21/12/18 18:49:54 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：2015entropy40 0.860563475797644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 18:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1028.0 KiB\n",
      "21/12/18 18:50:14 WARN DAGScheduler: Broadcasting large task binary with size 1721.8 KiB\n",
      "21/12/18 18:50:16 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "21/12/18 18:50:19 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "21/12/18 18:50:22 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/18 18:50:24 WARN DAGScheduler: Broadcasting large task binary with size 1290.1 KiB\n",
      "21/12/18 18:50:26 WARN DAGScheduler: Broadcasting large task binary with size 10.5 MiB\n",
      "21/12/18 18:50:29 WARN DAGScheduler: Broadcasting large task binary with size 1766.3 KiB\n",
      "21/12/18 18:50:31 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n",
      "21/12/18 18:50:35 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/12/18 18:50:38 WARN DAGScheduler: Broadcasting large task binary with size 21.5 MiB\n",
      "21/12/18 18:50:43 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "21/12/18 18:50:47 WARN DAGScheduler: Broadcasting large task binary with size 29.0 MiB\n",
      "21/12/18 18:50:53 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "21/12/18 18:50:58 WARN DAGScheduler: Broadcasting large task binary with size 37.9 MiB\n",
      "21/12/18 18:51:07 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/18 18:51:15 WARN DAGScheduler: Broadcasting large task binary with size 47.7 MiB\n",
      "21/12/18 18:51:24 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "21/12/18 18:51:32 WARN DAGScheduler: Broadcasting large task binary with size 58.0 MiB\n",
      "21/12/18 18:52:25 ERROR Executor: Exception in task 0.0 in stage 787.0 (TID 1289)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n",
      "\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n",
      "\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n",
      "\tat scala.Array$.tabulate(Array.scala:418)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "21/12/18 18:52:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 0.0 in stage 787.0 (TID 1289),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n",
      "\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n",
      "\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n",
      "\tat scala.Array$.tabulate(Array.scala:418)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "21/12/18 18:52:25 WARN TaskSetManager: Lost task 0.0 in stage 787.0 (TID 1289) (192.168.0.105 executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n",
      "\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n",
      "\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n",
      "\tat scala.Array$.tabulate(Array.scala:418)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "21/12/18 18:52:25 ERROR TaskSetManager: Task 0 in stage 787.0 failed 1 times; aborting job\n",
      "21/12/18 18:52:25 ERROR Instrumentation: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 787.0 failed 1 times, most recent failure: Lost task 0.0 in stage 787.0 (TID 1289) (192.168.0.105 executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n",
      "\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n",
      "\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n",
      "\tat scala.Array$.tabulate(Array.scala:418)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2352)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2351)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1109)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1109)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1109)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2591)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2533)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:898)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:737)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:736)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.findBestSplits(RandomForest.scala:663)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.runBagged(RandomForest.scala:208)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:302)\n",
      "\tat org.apache.spark.ml.classification.RandomForestClassifier.$anonfun$train$1(RandomForestClassifier.scala:161)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n",
      "\tat org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:138)\n",
      "\tat org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:46)\n",
      "\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n",
      "\tat sun.reflect.GeneratedMethodAccessor154.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n",
      "\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n",
      "\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n",
      "\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n",
      "\tat scala.Array$.tabulate(Array.scala:418)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n",
      "\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "\n",
      "21/12/18 18:52:25 WARN TaskSetManager: Lost task 1.0 in stage 787.0 (TID 1290) (192.168.0.105 executor driver): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3380.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 787.0 failed 1 times, most recent failure: Lost task 0.0 in stage 787.0 (TID 1289) (192.168.0.105 executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n\tat scala.Array$.tabulate(Array.scala:418)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2352)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2351)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2351)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1109)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1109)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1109)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2591)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2533)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:898)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:737)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:736)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.findBestSplits(RandomForest.scala:663)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.runBagged(RandomForest.scala:208)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:302)\n\tat org.apache.spark.ml.classification.RandomForestClassifier.$anonfun$train$1(RandomForestClassifier.scala:161)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:138)\n\tat org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:46)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat sun.reflect.GeneratedMethodAccessor154.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n\tat scala.Array$.tabulate(Array.scala:418)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13682/2973331101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpurity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimpurity_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmaxBins\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaxBins_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mrf_classifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'is_default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumTrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumTrees\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxDepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxDepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimpurity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimpurity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxBins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxBins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mrf_predictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawPredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rawPrediction'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'is_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/spark-3.2.0-bin-hadoop3.2/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/spark-3.2.0-bin-hadoop3.2/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/spark-3.2.0-bin-hadoop3.2/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/spark-3.2.0-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3380.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 787.0 failed 1 times, most recent failure: Lost task 0.0 in stage 787.0 (TID 1289) (192.168.0.105 executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n\tat scala.Array$.tabulate(Array.scala:418)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2352)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2351)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2351)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1109)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1109)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1109)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2591)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2533)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:898)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:737)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:736)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.findBestSplits(RandomForest.scala:663)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.runBagged(RandomForest.scala:208)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:302)\n\tat org.apache.spark.ml.classification.RandomForestClassifier.$anonfun$train$1(RandomForestClassifier.scala:161)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:138)\n\tat org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:46)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat sun.reflect.GeneratedMethodAccessor154.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator$$Lambda$3574/1330471226.get$Lambda(Unknown Source)\n\tat java.lang.invoke.LambdaForm$DMH/245672235.invokeStatic_L_L(LambdaForm$DMH)\n\tat java.lang.invoke.LambdaForm$MH/2068562923.linkToTargetMethod(LambdaForm$MH)\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:54)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22(RandomForest.scala:651)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$22$adapted(RandomForest.scala:647)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3571/1318815440.apply(Unknown Source)\n\tat scala.Array$.tabulate(Array.scala:418)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.$anonfun$findBestSplits$21(RandomForest.scala:647)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$$Lambda$3552/332149708.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD$$Lambda$2621/1999655490.apply(Unknown Source)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2377/167528220.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "numTrees_list = [20,50,100,150,200,300]\n",
    "maxDepth_list = [5,10,15,20,30,40,50]\n",
    "impurity_list = ['gini', 'entropy']\n",
    "maxBins_list = [24,32,40]\n",
    "for numTrees in numTrees_list:\n",
    "    for maxDepth in maxDepth_list:\n",
    "        for impurity in impurity_list:\n",
    "            for maxBins in maxBins_list:\n",
    "                rf_classifier=RandomForestClassifier(labelCol='is_default', featuresCol=\"features\",numTrees=numTrees,maxDepth=maxDepth,impurity=impurity,maxBins=maxBins).fit(train_df)  \n",
    "                rf_predictions=rf_classifier.transform(test_df)\n",
    "                evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='is_default')\n",
    "                print('AUC：'+str(numTrees)+str(maxDepth)+impurity+str(maxBins), evaluator.evaluate(rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849dfa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf_classifier=RandomForestClassifier(labelCol='is_default', featuresCol=\"features\",numTrees=20,maxDepth=5,impurity='entropy').fit(train_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ea8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions=rf_classifier.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67be297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC： 0.8015992903530811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='is_default')\n",
    "print('AUC：', evaluator.evaluate(rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b2a90",
   "metadata": {},
   "source": [
    "gbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e73b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gbt_classifier = GBTClassifier(labelCol='is_default', featuresCol=\"features\", maxIter=15).fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f66763",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_predictions=gbt_classifier.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "681f005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC： 0.8131785792222486\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='is_default')\n",
    "print('AUC：', evaluator.evaluate(rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764a428",
   "metadata": {},
   "source": [
    "MLPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87904e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [38,50,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0507ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPC_trainer = MultilayerPerceptronClassifier(labelCol='is_default', featuresCol=\"features\", maxIter=100, layers=layers, blockSize=128, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57dd4cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/19 17:05:56 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/12/19 17:05:56 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "MLPC_model = MLPC_trainer.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a828ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPC_predictions = MLPC_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb6811e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC： 0.641615563116166\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='is_default')\n",
    "print('AUC：', evaluator.evaluate(MLPC_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d577436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
